{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도전문제: 파일의 단어 갯수 세기\n",
    "- 총 단어수\n",
    "- 고유 단어수\n",
    "- 가장 많이 사용된 단어 10개"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1. 파일에서 데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lorem.txt', 'r') as file:\n",
    "    contents = file.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2. 구둣점을 제거하고 소문자로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "clean_contents = re.sub('['+string.punctuation+']','', contents).lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3. 공백으로 분리하여 words 리스트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'lorem', 'ipsum', 'lorem']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = clean_contents.split()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 단어수는 511 이고, 고유 단어수는 256 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 총 단어수\n",
    "print(f'총 단어수는 {len(words)} 이고, 고유 단어수는 {len(set(words))} 입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 4. 고유단어가 key이고, 빈도가 value인 딕셔너리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'what': 1,\n",
       " 'is': 8,\n",
       " 'lorem': 19,\n",
       " 'ipsum': 19,\n",
       " 'simply': 2,\n",
       " 'dummy': 2,\n",
       " 'text': 5,\n",
       " 'of': 21,\n",
       " 'the': 28,\n",
       " 'printing': 1,\n",
       " 'and': 10,\n",
       " 'typesetting': 2,\n",
       " 'industry': 1,\n",
       " 'has': 4,\n",
       " 'been': 1,\n",
       " 'industrys': 1,\n",
       " 'standard': 2,\n",
       " 'ever': 1,\n",
       " 'since': 2,\n",
       " '1500s': 2,\n",
       " 'when': 2,\n",
       " 'an': 1,\n",
       " 'unknown': 1,\n",
       " 'printer': 1,\n",
       " 'took': 1,\n",
       " 'a': 15,\n",
       " 'galley': 1,\n",
       " 'type': 2,\n",
       " 'scrambled': 1,\n",
       " 'it': 11,\n",
       " 'to': 7,\n",
       " 'make': 1,\n",
       " 'specimen': 1,\n",
       " 'book': 2,\n",
       " 'survived': 1,\n",
       " 'not': 2,\n",
       " 'only': 1,\n",
       " 'five': 1,\n",
       " 'centuries': 1,\n",
       " 'but': 2,\n",
       " 'also': 2,\n",
       " 'leap': 1,\n",
       " 'into': 1,\n",
       " 'electronic': 1,\n",
       " 'remaining': 1,\n",
       " 'essentially': 1,\n",
       " 'unchanged': 1,\n",
       " 'was': 1,\n",
       " 'popularised': 1,\n",
       " 'in': 10,\n",
       " '1960s': 1,\n",
       " 'with': 3,\n",
       " 'release': 1,\n",
       " 'letraset': 1,\n",
       " 'sheets': 1,\n",
       " 'containing': 1,\n",
       " 'passages': 2,\n",
       " 'more': 2,\n",
       " 'recently': 1,\n",
       " 'desktop': 2,\n",
       " 'publishing': 2,\n",
       " 'software': 1,\n",
       " 'like': 3,\n",
       " 'aldus': 1,\n",
       " 'pagemaker': 1,\n",
       " 'including': 1,\n",
       " 'versions': 3,\n",
       " 'why': 1,\n",
       " 'do': 1,\n",
       " 'we': 1,\n",
       " 'use': 3,\n",
       " 'long': 1,\n",
       " 'established': 1,\n",
       " 'fact': 1,\n",
       " 'that': 2,\n",
       " 'reader': 1,\n",
       " 'will': 2,\n",
       " 'be': 2,\n",
       " 'distracted': 1,\n",
       " 'by': 7,\n",
       " 'readable': 2,\n",
       " 'content': 3,\n",
       " 'page': 2,\n",
       " 'looking': 1,\n",
       " 'at': 2,\n",
       " 'its': 1,\n",
       " 'layout': 1,\n",
       " 'point': 1,\n",
       " 'using': 2,\n",
       " 'moreorless': 1,\n",
       " 'normal': 1,\n",
       " 'distribution': 1,\n",
       " 'letters': 1,\n",
       " 'as': 3,\n",
       " 'opposed': 1,\n",
       " 'here': 2,\n",
       " 'making': 3,\n",
       " 'look': 2,\n",
       " 'english': 2,\n",
       " 'many': 3,\n",
       " 'packages': 1,\n",
       " 'web': 2,\n",
       " 'editors': 1,\n",
       " 'now': 1,\n",
       " 'their': 3,\n",
       " 'default': 1,\n",
       " 'model': 2,\n",
       " 'search': 1,\n",
       " 'for': 2,\n",
       " 'uncover': 1,\n",
       " 'sites': 1,\n",
       " 'still': 1,\n",
       " 'infancy': 1,\n",
       " 'various': 1,\n",
       " 'have': 2,\n",
       " 'evolved': 1,\n",
       " 'over': 3,\n",
       " 'years': 2,\n",
       " 'sometimes': 2,\n",
       " 'accident': 1,\n",
       " 'on': 4,\n",
       " 'purpose': 1,\n",
       " 'injected': 3,\n",
       " 'humour': 3,\n",
       " 'where': 2,\n",
       " 'does': 1,\n",
       " 'come': 1,\n",
       " 'from': 8,\n",
       " 'contrary': 1,\n",
       " 'popular': 2,\n",
       " 'belief': 1,\n",
       " 'random': 1,\n",
       " 'roots': 1,\n",
       " 'piece': 1,\n",
       " 'classical': 2,\n",
       " 'latin': 4,\n",
       " 'literature': 2,\n",
       " '45': 2,\n",
       " 'bc': 2,\n",
       " '2000': 1,\n",
       " 'old': 1,\n",
       " 'richard': 1,\n",
       " 'mcclintock': 1,\n",
       " 'professor': 1,\n",
       " 'hampdensydney': 1,\n",
       " 'college': 1,\n",
       " 'virginia': 1,\n",
       " 'looked': 1,\n",
       " 'up': 1,\n",
       " 'one': 1,\n",
       " 'obscure': 1,\n",
       " 'words': 4,\n",
       " 'consectetur': 1,\n",
       " 'passage': 2,\n",
       " 'going': 2,\n",
       " 'through': 1,\n",
       " 'cites': 1,\n",
       " 'word': 1,\n",
       " 'discovered': 1,\n",
       " 'undoubtable': 1,\n",
       " 'source': 1,\n",
       " 'comes': 2,\n",
       " 'sections': 2,\n",
       " '11032': 3,\n",
       " '11033': 2,\n",
       " 'de': 2,\n",
       " 'finibus': 2,\n",
       " 'bonorum': 2,\n",
       " 'et': 2,\n",
       " 'malorum': 2,\n",
       " 'extremes': 1,\n",
       " 'good': 1,\n",
       " 'evil': 1,\n",
       " 'cicero': 2,\n",
       " 'written': 1,\n",
       " 'this': 2,\n",
       " 'treatise': 1,\n",
       " 'theory': 1,\n",
       " 'ethics': 1,\n",
       " 'very': 1,\n",
       " 'during': 1,\n",
       " 'renaissance': 1,\n",
       " 'first': 2,\n",
       " 'line': 2,\n",
       " 'dolor': 1,\n",
       " 'sit': 1,\n",
       " 'amet': 1,\n",
       " 'section': 1,\n",
       " 'chunk': 1,\n",
       " 'used': 1,\n",
       " 'reproduced': 2,\n",
       " 'below': 1,\n",
       " 'those': 1,\n",
       " 'interested': 1,\n",
       " 'are': 3,\n",
       " 'exact': 1,\n",
       " 'original': 1,\n",
       " 'form': 2,\n",
       " 'accompanied': 1,\n",
       " '1914': 1,\n",
       " 'translation': 1,\n",
       " 'h': 1,\n",
       " 'rackham': 1,\n",
       " 'can': 1,\n",
       " 'i': 1,\n",
       " 'get': 1,\n",
       " 'some': 2,\n",
       " 'there': 2,\n",
       " 'variations': 1,\n",
       " 'available': 1,\n",
       " 'majority': 1,\n",
       " 'suffered': 1,\n",
       " 'alteration': 1,\n",
       " 'or': 2,\n",
       " 'randomised': 1,\n",
       " 'which': 2,\n",
       " 'dont': 1,\n",
       " 'even': 1,\n",
       " 'slightly': 1,\n",
       " 'believable': 1,\n",
       " 'if': 1,\n",
       " 'you': 2,\n",
       " 'need': 1,\n",
       " 'sure': 1,\n",
       " 'isnt': 1,\n",
       " 'anything': 1,\n",
       " 'embarrassing': 1,\n",
       " 'hidden': 1,\n",
       " 'middle': 1,\n",
       " 'all': 1,\n",
       " 'generators': 1,\n",
       " 'internet': 2,\n",
       " 'tend': 1,\n",
       " 'repeat': 1,\n",
       " 'predefined': 1,\n",
       " 'chunks': 1,\n",
       " 'necessary': 1,\n",
       " 'true': 1,\n",
       " 'generator': 1,\n",
       " 'uses': 1,\n",
       " 'dictionary': 1,\n",
       " '200': 1,\n",
       " 'combined': 1,\n",
       " 'handful': 1,\n",
       " 'sentence': 1,\n",
       " 'structures': 1,\n",
       " 'generate': 1,\n",
       " 'looks': 1,\n",
       " 'reasonable': 1,\n",
       " 'generated': 1,\n",
       " 'therefore': 1,\n",
       " 'always': 1,\n",
       " 'free': 1,\n",
       " 'repetition': 1,\n",
       " 'noncharacteristic': 1,\n",
       " 'etc': 1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for word in words:\n",
    "    if word in dic.keys():\n",
    "        dic[word] += 1\n",
    "    else:\n",
    "        dic[word] = 1\n",
    "dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 5. 빈도의 내림차순으로 딕셔너리 정렬하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 28), ('of', 21), ('lorem', 19), ('ipsum', 19), ('a', 15)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
